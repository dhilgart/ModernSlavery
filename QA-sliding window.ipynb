{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook for experimenting with a zero-shot sliding-window Question-Answering model approach to the task of classifying documents based on whether or not they give evidence that the company submitting the document has provided any training about modern slavery to their employees. \n",
    "\n",
    "The motivation is to use transfer learning from models pre-trained to extract relevant answers (as a span) from a document (context) in order to automate the identification of which small subsets of the documents might be relevant to modern slavery training. These smaller subsets can then make the job of human-labelling additional documents more efficient or be fed into another model (perhaps a transformer trained for sequence classification) which can only handle a limited number of tokens.\n",
    "\n",
    "The idea behind the approach is to use a pretrained QA model (one trained on SQuAD v2 such that it can return a \"no span found\" result) to ask questions of the documents. Since most documents in the dataset are longer than the maximum input length, a sliding window approach is used: after the entire document is tokenized, the QA model is run on successive windows, each slid by stride=128 tokens (~1/4th of the window size). All spans returned by the QA model are recorded in a new dataframe (df_with_segments.parquet). A notebook for visualizing the results of the sliding-window QA model approach is available: 'QA results viewer.ipynb'\n",
    "\n",
    "Six questions are trialed to see which one(s) provide the best results:\n",
    " - 'Is there training provided?'\n",
    " - 'Is there training already in place?'\n",
    " - 'Has training been done?'\n",
    " - 'Is training planned?'\n",
    " - 'Is training in development?'\n",
    " - 'What kind of training is provided?'\n",
    "\n",
    "Note: as this is a zero-shot approach, we can ignore the labels as we will not be doing any training. Therefore, the labeled (train) and unlabeled (test) data will be concatenated into a single input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.6.0 available.\n",
      "TensorFlow version 2.3.0 available.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>source</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>labeled</td>\n",
       "      <td>Modern Slavery Statement\\n\\nUa\\n\\n&gt; Responsibi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>labeled</td>\n",
       "      <td>Burton's Biscuit Company (a trading name of Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>labeled</td>\n",
       "      <td>MODERN SLAVERY ACT STATEMENT\\nOUR BUSINESS Zal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>labeled</td>\n",
       "      <td>MENU\\nHOME\\nU.K. MODERN SLAVERY ACT STATEMENT\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>labeled</td>\n",
       "      <td>Modern Slavery Act Statement\\nIntroduction fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>326</td>\n",
       "      <td>hidden</td>\n",
       "      <td>CECP Advisors LLP Modern Slavery Act Statement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>327</td>\n",
       "      <td>hidden</td>\n",
       "      <td>Modern Slavery Act Transparency Statement\\n201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>328</td>\n",
       "      <td>hidden</td>\n",
       "      <td>MENU\\n\\n0333 2203 121\\nBOOK A ROOM\\n\\nAnti Sla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>329</td>\n",
       "      <td>hidden</td>\n",
       "      <td>We have placed cookies on your computer, as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>330</td>\n",
       "      <td>hidden</td>\n",
       "      <td>PARTNERSHIP\\nThe UK Modern Slavery Act 2015\\nO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>981 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID   source                                               TEXT\n",
       "0      0  labeled  Modern Slavery Statement\\n\\nUa\\n\\n> Responsibi...\n",
       "1      1  labeled  Burton's Biscuit Company (a trading name of Bu...\n",
       "2      2  labeled  MODERN SLAVERY ACT STATEMENT\\nOUR BUSINESS Zal...\n",
       "3      3  labeled  MENU\\nHOME\\nU.K. MODERN SLAVERY ACT STATEMENT\\...\n",
       "4      4  labeled  Modern Slavery Act Statement\\nIntroduction fro...\n",
       "..   ...      ...                                                ...\n",
       "976  326   hidden  CECP Advisors LLP Modern Slavery Act Statement...\n",
       "977  327   hidden  Modern Slavery Act Transparency Statement\\n201...\n",
       "978  328   hidden  MENU\\n\\n0333 2203 121\\nBOOK A ROOM\\n\\nAnti Sla...\n",
       "979  329   hidden  We have placed cookies on your computer, as th...\n",
       "980  330   hidden  PARTNERSHIP\\nThe UK Modern Slavery Act 2015\\nO...\n",
       "\n",
       "[981 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data, strip away the labels and combine into a single df\n",
    "df_labeled=pd.read_csv('train (3).csv',index_col=0)\n",
    "df_hidden=pd.read_csv('test (3).csv',index_col=0)\n",
    "df_labeled['source']='labeled'\n",
    "df_hidden['source']='hidden'\n",
    "df = pd.concat([df_labeled[['source','TEXT']], \n",
    "                df_hidden[['source','TEXT']]],axis=0).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any characters repeated more than 4 times will be shortened to 4 repetitions: \n",
    "# https://stackoverflow.com/questions/10072744/remove-repeating-characters-from-words\n",
    "df['TEXT']=df['TEXT'].apply(lambda x: re.sub(r'(.)\\1{4,}', r'\\1\\1\\1\\1', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/ktrapeznikov/albert-xlarge-v2-squad-v2/config.json from cache at C:\\Users\\dhilg/.cache\\torch\\transformers\\c63acbd2ffb1762d161c0c366bb4a0dd5312f615847b87d4cf7be001ca562cab.0aa9a4e13357b14219e56e90005cf95adfc4fbb59ad847974267550fef9c2f6f\n",
      "Model config AlbertConfig {\n",
      "  \"architectures\": [\n",
      "    \"AlbertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "Model name 'ktrapeznikov/albert-xlarge-v2-squad-v2' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming 'ktrapeznikov/albert-xlarge-v2-squad-v2' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/ktrapeznikov/albert-xlarge-v2-squad-v2/spiece.model from cache at C:\\Users\\dhilg/.cache\\torch\\transformers\\7965d016e61ef4d252f6147c2fe018bdedda12de9252654783b3e123b23c9166.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/ktrapeznikov/albert-xlarge-v2-squad-v2/added_tokens.json from cache at C:\\Users\\dhilg/.cache\\torch\\transformers\\2be0ba3861214ce9e158f728d67400006704ea0b37ecb577ed22fd68c80780fa.3889713104075cfee9e96090bcdd0dc753733b3db9da20d1dd8b2cd1030536a2\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/ktrapeznikov/albert-xlarge-v2-squad-v2/special_tokens_map.json from cache at C:\\Users\\dhilg/.cache\\torch\\transformers\\a567087ca424c8bff169eada361523a2dacd7aa4b9b291bdc197d40fe838cb10.4f0d42b1849e2d6fd72c735fba48dff0d2f0a55f5d1961e79bcfce337d354167\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/ktrapeznikov/albert-xlarge-v2-squad-v2/tokenizer_config.json from cache at C:\\Users\\dhilg/.cache\\torch\\transformers\\17d58b6e4b5edb11982eea737b2c5f09312964c1ac0021b5e84c10eed3fa0663.3fc3a7b9028b25d25e6393f1d27ed643eb6ba9ce4113c05aa13277951cff117c\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/ktrapeznikov/albert-xlarge-v2-squad-v2/tokenizer.json from cache at None\n",
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/ktrapeznikov/albert-xlarge-v2-squad-v2/config.json from cache at C:\\Users\\dhilg/.cache\\torch\\transformers\\c63acbd2ffb1762d161c0c366bb4a0dd5312f615847b87d4cf7be001ca562cab.0aa9a4e13357b14219e56e90005cf95adfc4fbb59ad847974267550fef9c2f6f\n",
      "Model config AlbertConfig {\n",
      "  \"architectures\": [\n",
      "    \"AlbertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"down_scale_factor\": 1,\n",
      "  \"embedding_size\": 128,\n",
      "  \"eos_token_id\": 3,\n",
      "  \"gap_size\": 0,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"inner_group_num\": 1,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"albert\",\n",
      "  \"net_structure_type\": 0,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_groups\": 1,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_memory_blocks\": 0,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://cdn.huggingface.co/ktrapeznikov/albert-xlarge-v2-squad-v2/pytorch_model.bin from cache at C:\\Users\\dhilg/.cache\\torch\\transformers\\49e7ccd95cebd1b8210607e08d6d9ad7dccd760db94a9a409c19a93f9ec5594c.e63d894d1c8b12d9da1be391592635fa9414da143b07cc6d63895911e2df8fb2\n",
      "All model checkpoint weights were used when initializing AlbertForQuestionAnswering.\n",
      "\n",
      "All the weights of AlbertForQuestionAnswering were initialized from the model checkpoint at ktrapeznikov/albert-xlarge-v2-squad-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlbertForQuestionAnswering(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=2048, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (key): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (value): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "                (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "                (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "                (LayerNorm): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "              (ffn_output): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model chosen based on SQuAD v2 leaderboards December 2020\n",
    "model_name = 'ktrapeznikov/albert-xlarge-v2-squad-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tokens(model, tokenizer, questions, tokens, max_batch_size=8, max_model_tokens=512, stride=64):\n",
    "    num_tokens = tokens.size()[1]\n",
    "    token_classes = torch.zeros((len(questions), num_tokens), dtype=torch.long)\n",
    "\n",
    "    batch_details=[]\n",
    "    for i, question in enumerate(questions):\n",
    "        question_tokens = tokenizer(question, return_tensors='pt')['input_ids']\n",
    "        num_question_tokens = question_tokens.size()[1]\n",
    "        max_context_tokens = max_model_tokens - num_question_tokens - 1 # -1 for the [SEP] token that will be added to the end\n",
    "\n",
    "        num_windows = max(1, -(-(num_tokens - max_context_tokens) // stride) + 1)\n",
    "        \n",
    "        for j in range(num_windows):\n",
    "            end = min(j*stride + max_context_tokens, num_tokens)\n",
    "            start = max(0, end - max_context_tokens)\n",
    "            batch_details.append({'question number':i,\n",
    "                                  'question tokens':question_tokens,\n",
    "                                  'token start':start,\n",
    "                                  'token end':end\n",
    "                                 })\n",
    "            if len(batch_details) >= max_batch_size or (i==len(questions) and j==num_windows):\n",
    "                token_classes = run_batch(model, tokens, token_classes, batch_details)\n",
    "                batch_details = []\n",
    "    \n",
    "    return token_classes\n",
    "\n",
    "def run_batch(model, tokens, token_classes, batch_details):\n",
    "    inputs = batch_inputs(tokens, batch_details)\n",
    "    \n",
    "    answer_start_logits, answer_end_logits = model(**inputs)\n",
    "    \n",
    "    combined_logits = torch.cat([answer_start_logits.unsqueeze(0), answer_end_logits.unsqueeze(0)])\n",
    "    span_input_ids = torch.max(combined_logits,2)[1]\n",
    "    span_input_ids[1] += 1 # need to add 1 to end token of span\n",
    "    \n",
    "    # need to slide the token ids to remove the question tokens from the front of the tensor:\n",
    "    input_question_lengths = torch.tensor([instance['question tokens'].size()[1] for instance in batch_details], \n",
    "                                          dtype=torch.long)\n",
    "    span_token_ids = torch.max(span_input_ids - input_question_lengths, \n",
    "                               torch.zeros_like(span_input_ids)) # if no span is found, the model will point to the first \n",
    "                                                                 # token of the question. After subtracting the question\n",
    "                                                                 # length, this would be negative, so set a floor of zero.\n",
    "    for i, instance in enumerate(batch_details):\n",
    "        # if a span was found, span_token_ids of the start token will be > 0\n",
    "        if span_token_ids[0,i] > 0:\n",
    "            span_token_start = span_token_ids[0,i] + instance['token start']\n",
    "            span_token_end = span_token_ids[1,i] + instance['token start']\n",
    "            \n",
    "            token_classes[instance['question number'],span_token_start:span_token_end+1] = 1\n",
    "    \n",
    "    return token_classes\n",
    "    \n",
    "def batch_inputs(tokens, batch_details):\n",
    "    max_tokens = max_batch_tokens(batch_details)\n",
    "    batch_size = len(batch_details)\n",
    "    \n",
    "    inputs={'input_ids':torch.zeros(batch_size, max_tokens, dtype=torch.long),\n",
    "            'token_type_ids':torch.zeros(batch_size, max_tokens, dtype=torch.long),\n",
    "            'attention_mask':torch.zeros(batch_size, max_tokens, dtype=torch.long)\n",
    "           }\n",
    "    \n",
    "    for i, instance in enumerate(batch_details):\n",
    "        question_tokens = instance['question tokens']\n",
    "        context_tokens = tokens[:, instance['token start']:instance['token end']]\n",
    "        \n",
    "        question_length = question_tokens.size()[1]\n",
    "        context_length = context_tokens.size()[1]\n",
    "        \n",
    "        inputs['input_ids'][i, :question_length]=question_tokens.squeeze(0)\n",
    "        inputs['input_ids'][i, question_length:question_length+context_length]=context_tokens.squeeze(0)\n",
    "        # add final [SEP] token after context (same as final token of question tokens)\n",
    "        inputs['input_ids'][i, -1]=question_tokens.squeeze(0)[-1]\n",
    "        \n",
    "        inputs['token_type_ids'][i, question_length:] = 1\n",
    "        inputs['attention_mask'][i, :question_length+context_length+1] = 1\n",
    "    return inputs\n",
    "\n",
    "def max_batch_tokens(batch_details):\n",
    "    max_tokens = 0\n",
    "    for instance in batch_details:\n",
    "        num_question_tokens = instance['question tokens'].size()[1] - 2 # don't count the [CLS] and [SEP] tokens\n",
    "        num_context_tokens = instance['token end'] - instance['token start']\n",
    "        instance_tokens = 1 + num_question_tokens + 1 + num_context_tokens + 1\n",
    "        if instance_tokens > max_tokens:\n",
    "            max_tokens = instance_tokens\n",
    "    return max_tokens\n",
    "\n",
    "def process_text(text, model, tokenizer, questions, max_batch_size=8, max_model_tokens=512, stride=64):\n",
    "    tokens = tokenizer(text, return_tensors='pt')['input_ids'][:,1:-1] # drop first and last tokens ([CLS] and [SEP])\n",
    "    \n",
    "    token_classes = classify_tokens(model, tokenizer, questions, tokens, max_batch_size, max_model_tokens, stride)\n",
    "    \n",
    "    filtered_text=[]\n",
    "    for i, question in enumerate(questions):\n",
    "        filtered_text.append({'question':question,\n",
    "                              'text segments':token_classes_to_str(tokenizer, tokens, token_classes[i])\n",
    "                             })\n",
    "    \n",
    "    return filtered_text\n",
    "\n",
    "def token_classes_to_str(tokenizer, tokens, token_classes):\n",
    "    spans = identify_distinct_spans(token_classes)\n",
    "    \n",
    "    text_segments = []\n",
    "    for span_start, span_end in spans:\n",
    "        text_segments.append(tokens_to_str(tokenizer, tokens, span_start, span_end))\n",
    "        \n",
    "    return text_segments\n",
    "\n",
    "def tokens_to_str(tokenizer, tokens, span_start, span_end):\n",
    "    return tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(tokens[0][span_start:span_end+1]))\n",
    "        \n",
    "def identify_distinct_spans(token_classes):\n",
    "    spans=[]\n",
    "    last_token_class=0\n",
    "    for i in range(token_classes.size()[0]):\n",
    "        curr_token_class = token_classes[i]\n",
    "        if last_token_class != curr_token_class:\n",
    "            if last_token_class == 0:\n",
    "                span_start = i\n",
    "            else:\n",
    "                span_end = i-1\n",
    "                spans.append((span_start, span_end))\n",
    "        last_token_class = curr_token_class\n",
    "    \n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row_id, model, tokenizer, questions, max_batch_size=8, max_model_tokens=512, stride=64):\n",
    "    filtered_text = process_text(text=df.loc[row_id,'TEXT'], \n",
    "                                 model=model, \n",
    "                                 tokenizer=tokenizer, \n",
    "                                 questions=questions, \n",
    "                                 max_batch_size=max_batch_size, \n",
    "                                 max_model_tokens=max_model_tokens, \n",
    "                                 stride=stride)\n",
    "    for question in filtered_text:\n",
    "        col_header = question['question']\n",
    "        text_segments = question['text segments']\n",
    "        for text_segment in text_segments:\n",
    "            df.loc[row_id,col_header].append(text_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=['Is there training provided?', \n",
    "           'Is there training already in place?',\n",
    "           'Has training been done?',\n",
    "           'Is training planned?',\n",
    "           'Is training in development?',\n",
    "           'What kind of training is provided?'\n",
    "          ]\n",
    "\n",
    "for question in questions:\n",
    "    df[question]=[[] for _ in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 finished at 2020-12-11 13:23:36.092920. Row time = 0:04:39.406075. Total time elapsed = 0:04:39.422217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1259 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 1 finished at 2020-12-11 13:29:26.767254. Row time = 0:05:50.567341. Total time elapsed = 0:10:30.081412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4146 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 2 finished at 2020-12-11 13:39:23.691940. Row time = 0:09:56.924686. Total time elapsed = 0:20:27.006098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 3 finished at 2020-12-11 14:09:51.656265. Row time = 0:30:27.963362. Total time elapsed = 0:50:54.970423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 4 finished at 2020-12-11 14:12:47.639705. Row time = 0:02:55.982467. Total time elapsed = 0:53:50.953863\n",
      "row 5 finished at 2020-12-11 14:15:48.211806. Row time = 0:03:00.572101. Total time elapsed = 0:56:51.525964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10428 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 6 finished at 2020-12-11 15:43:03.934920. Row time = 1:27:15.723114. Total time elapsed = 2:24:07.249078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2390 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 7 finished at 2020-12-11 15:44:23.530051. Row time = 0:01:19.594151. Total time elapsed = 2:25:26.844209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1593 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 8 finished at 2020-12-11 16:04:42.621350. Row time = 0:20:19.090298. Total time elapsed = 2:45:45.935508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 9 finished at 2020-12-11 16:15:32.542328. Row time = 0:10:49.920978. Total time elapsed = 2:56:35.856486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4410 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 10 finished at 2020-12-11 16:23:59.585311. Row time = 0:08:27.042983. Total time elapsed = 3:05:02.899469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 11 finished at 2020-12-11 17:02:23.627688. Row time = 0:38:24.041406. Total time elapsed = 3:43:26.941846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 12 finished at 2020-12-11 17:05:30.966617. Row time = 0:03:07.337932. Total time elapsed = 3:46:34.280775\n",
      "row 13 finished at 2020-12-11 17:16:44.760919. Row time = 0:11:13.789747. Total time elapsed = 3:57:48.075077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2571 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 14 finished at 2020-12-11 17:17:39.949863. Row time = 0:00:55.188944. Total time elapsed = 3:58:43.264021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1528 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 15 finished at 2020-12-11 17:37:13.558455. Row time = 0:19:33.607619. Total time elapsed = 4:18:16.872613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1423 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 16 finished at 2020-12-11 17:48:20.672066. Row time = 0:11:07.113611. Total time elapsed = 4:29:23.986224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 17 finished at 2020-12-11 18:02:47.742642. Row time = 0:14:27.070576. Total time elapsed = 4:43:51.056800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (731 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 18 finished at 2020-12-11 18:05:52.632819. Row time = 0:03:04.890177. Total time elapsed = 4:46:55.946977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 19 finished at 2020-12-11 18:10:15.918001. Row time = 0:04:23.285182. Total time elapsed = 4:51:19.232159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2634 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 20 finished at 2020-12-11 18:15:52.504273. Row time = 0:05:36.585299. Total time elapsed = 4:56:55.818431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (545 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 21 finished at 2020-12-11 18:40:23.151351. Row time = 0:24:30.646077. Total time elapsed = 5:21:26.465509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 22 finished at 2020-12-11 18:42:43.356001. Row time = 0:02:20.204650. Total time elapsed = 5:23:46.670159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 23 finished at 2020-12-11 18:45:43.298946. Row time = 0:02:59.942945. Total time elapsed = 5:26:46.613104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 24 finished at 2020-12-11 18:53:03.926073. Row time = 0:07:20.626124. Total time elapsed = 5:34:07.240231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 25 finished at 2020-12-11 18:57:22.597876. Row time = 0:04:18.671803. Total time elapsed = 5:38:25.912034\n",
      "row 26 finished at 2020-12-11 19:01:46.145388. Row time = 0:04:23.547512. Total time elapsed = 5:42:49.459546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1372 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 27 finished at 2020-12-11 19:02:55.615131. Row time = 0:01:09.469743. Total time elapsed = 5:43:58.929289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1159 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 28 finished at 2020-12-11 19:15:47.525204. Row time = 0:12:51.909082. Total time elapsed = 5:56:50.839362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 29 finished at 2020-12-11 19:25:58.397835. Row time = 0:10:10.872631. Total time elapsed = 6:07:01.711993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 30 finished at 2020-12-11 19:36:03.426142. Row time = 0:10:05.029279. Total time elapsed = 6:17:06.741272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1074 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 31 finished at 2020-12-11 19:46:08.305195. Row time = 0:10:04.878081. Total time elapsed = 6:27:11.619353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5282 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 32 finished at 2020-12-11 19:54:23.631190. Row time = 0:08:15.325033. Total time elapsed = 6:35:26.945348\n",
      "row 33 finished at 2020-12-11 21:00:22.094133. Row time = 1:05:58.462943. Total time elapsed = 7:41:25.408291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 34 finished at 2020-12-11 21:01:51.160775. Row time = 0:01:29.065642. Total time elapsed = 7:42:54.474933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 35 finished at 2020-12-11 21:19:01.343342. Row time = 0:17:10.181573. Total time elapsed = 8:00:04.657500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 36 finished at 2020-12-11 21:31:09.743296. Row time = 0:12:08.399954. Total time elapsed = 8:12:13.057454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 37 finished at 2020-12-11 21:38:45.797230. Row time = 0:07:36.033324. Total time elapsed = 8:19:49.111388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 38 finished at 2020-12-11 21:44:35.607063. Row time = 0:05:49.809833. Total time elapsed = 8:25:38.921221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1191 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 39 finished at 2020-12-11 21:50:16.454091. Row time = 0:05:40.847028. Total time elapsed = 8:31:19.768249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1774 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 40 finished at 2020-12-11 22:04:20.449046. Row time = 0:14:03.993962. Total time elapsed = 8:45:23.763204\n",
      "row 41 finished at 2020-12-11 22:26:27.052201. Row time = 0:22:06.602154. Total time elapsed = 9:07:30.366359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 42 finished at 2020-12-11 22:27:33.017024. Row time = 0:01:05.930266. Total time elapsed = 9:08:36.331182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 43 finished at 2020-12-11 22:33:03.411308. Row time = 0:05:30.394284. Total time elapsed = 9:14:06.725466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 44 finished at 2020-12-11 22:46:06.960249. Row time = 0:13:03.548941. Total time elapsed = 9:27:10.274407\n",
      "row 45 finished at 2020-12-11 22:53:36.847106. Row time = 0:07:29.885853. Total time elapsed = 9:34:40.161264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1995 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 46 finished at 2020-12-11 22:53:48.444753. Row time = 0:00:11.597647. Total time elapsed = 9:34:51.758911\n",
      "row 47 finished at 2020-12-11 23:09:18.324254. Row time = 0:15:29.878496. Total time elapsed = 9:50:21.638412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (745 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 48 finished at 2020-12-11 23:10:38.606398. Row time = 0:01:20.281143. Total time elapsed = 9:51:41.921554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1282 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 49 finished at 2020-12-11 23:15:28.520024. Row time = 0:04:49.911627. Total time elapsed = 9:56:31.834182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1201 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 50 finished at 2020-12-11 23:27:13.267484. Row time = 0:11:44.746491. Total time elapsed = 10:08:16.581642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1246 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 51 finished at 2020-12-11 23:36:25.151194. Row time = 0:09:11.883710. Total time elapsed = 10:17:28.465352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 52 finished at 2020-12-11 23:45:31.398995. Row time = 0:09:06.246802. Total time elapsed = 10:26:34.713153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2122 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 53 finished at 2020-12-11 23:48:10.841440. Row time = 0:02:39.441449. Total time elapsed = 10:29:14.155598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2117 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 54 finished at 2020-12-12 00:06:24.646199. Row time = 0:18:13.803755. Total time elapsed = 10:47:27.960357\n",
      "row 55 finished at 2020-12-12 00:25:13.548944. Row time = 0:18:48.901776. Total time elapsed = 11:06:16.863102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1751 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 56 finished at 2020-12-12 00:25:36.484904. Row time = 0:00:22.934961. Total time elapsed = 11:06:39.799062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1127 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 57 finished at 2020-12-12 00:40:31.903388. Row time = 0:14:55.418484. Total time elapsed = 11:21:35.217546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 58 finished at 2020-12-12 00:48:41.177361. Row time = 0:08:09.273973. Total time elapsed = 11:29:44.491519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1705 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 59 finished at 2020-12-12 00:52:35.960213. Row time = 0:03:54.781859. Total time elapsed = 11:33:39.274371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1413 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 60 finished at 2020-12-12 01:06:40.559340. Row time = 0:14:04.598127. Total time elapsed = 11:47:43.873498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 61 finished at 2020-12-12 01:18:42.911806. Row time = 0:12:02.352466. Total time elapsed = 11:59:46.225964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (944 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 62 finished at 2020-12-12 01:21:25.226232. Row time = 0:02:42.314426. Total time elapsed = 12:02:28.540390\n",
      "row 63 finished at 2020-12-12 01:28:17.531437. Row time = 0:06:52.305205. Total time elapsed = 12:09:20.845595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 64 finished at 2020-12-12 01:29:36.626644. Row time = 0:01:19.094209. Total time elapsed = 12:10:39.940802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2491 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 65 finished at 2020-12-12 01:37:31.917365. Row time = 0:07:55.289722. Total time elapsed = 12:18:35.231523\n",
      "row 66 finished at 2020-12-12 01:59:12.613177. Row time = 0:21:40.694844. Total time elapsed = 12:40:15.927335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (531 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 67 finished at 2020-12-12 01:59:38.801161. Row time = 0:00:26.187984. Total time elapsed = 12:40:42.115319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1411 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 68 finished at 2020-12-12 02:02:20.984079. Row time = 0:02:42.182918. Total time elapsed = 12:43:24.298237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 69 finished at 2020-12-12 02:14:06.445882. Row time = 0:11:45.460801. Total time elapsed = 12:55:09.760040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1378 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 70 finished at 2020-12-12 02:19:26.710891. Row time = 0:05:20.265009. Total time elapsed = 13:00:30.025049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 71 finished at 2020-12-12 02:29:56.519087. Row time = 0:10:29.808196. Total time elapsed = 13:10:59.833245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2065 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 72 finished at 2020-12-12 02:33:55.150333. Row time = 0:03:58.630247. Total time elapsed = 13:14:58.464491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1180 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 73 finished at 2020-12-12 02:52:12.626841. Row time = 0:18:17.475534. Total time elapsed = 13:33:15.940999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (715 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 74 finished at 2020-12-12 03:01:23.491527. Row time = 0:09:10.864686. Total time elapsed = 13:42:26.805685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2031 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 75 finished at 2020-12-12 03:05:22.240456. Row time = 0:03:58.747933. Total time elapsed = 13:46:25.554614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2552 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 76 finished at 2020-12-12 03:22:17.510521. Row time = 0:16:55.270065. Total time elapsed = 14:03:20.824679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1363 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 77 finished at 2020-12-12 03:46:05.415723. Row time = 0:23:47.905202. Total time elapsed = 14:27:08.729881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1307 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 78 finished at 2020-12-12 03:56:11.834944. Row time = 0:10:06.418257. Total time elapsed = 14:37:15.149102\n",
      "row 79 finished at 2020-12-12 04:06:38.333249. Row time = 0:10:26.498305. Total time elapsed = 14:47:41.647407\n",
      "row 80 finished at 2020-12-12 04:07:46.425856. Row time = 0:01:08.092607. Total time elapsed = 14:48:49.740014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1234 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 81 finished at 2020-12-12 04:08:52.761846. Row time = 0:01:06.335990. Total time elapsed = 14:49:56.076004\n",
      "row 82 finished at 2020-12-12 04:18:01.530790. Row time = 0:09:08.768944. Total time elapsed = 14:59:04.844948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (877 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 83 finished at 2020-12-12 04:19:15.100520. Row time = 0:01:13.569730. Total time elapsed = 15:00:18.414678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1352 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 84 finished at 2020-12-12 04:24:32.734221. Row time = 0:05:17.632731. Total time elapsed = 15:05:36.048379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 85 finished at 2020-12-12 04:35:02.674629. Row time = 0:10:29.939409. Total time elapsed = 15:16:05.988787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1049 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 86 finished at 2020-12-12 04:37:42.312424. Row time = 0:02:39.637795. Total time elapsed = 15:18:45.626582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 87 finished at 2020-12-12 04:45:37.588462. Row time = 0:07:55.276038. Total time elapsed = 15:26:40.902620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1311 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 88 finished at 2020-12-12 04:49:36.412062. Row time = 0:03:58.823600. Total time elapsed = 15:30:39.726220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 89 finished at 2020-12-12 05:00:02.355086. Row time = 0:10:25.943024. Total time elapsed = 15:41:05.669244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3122 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 90 finished at 2020-12-12 05:13:05.491327. Row time = 0:13:03.136241. Total time elapsed = 15:54:08.805485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (841 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 91 finished at 2020-12-12 05:41:42.550561. Row time = 0:28:37.059234. Total time elapsed = 16:22:45.864719\n",
      "row 92 finished at 2020-12-12 05:46:56.138168. Row time = 0:05:13.586605. Total time elapsed = 16:27:59.452326\n",
      "row 93 finished at 2020-12-12 05:47:42.083597. Row time = 0:00:45.945429. Total time elapsed = 16:28:45.397755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7404 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 94 finished at 2020-12-12 06:59:10.853710. Row time = 1:11:28.769142. Total time elapsed = 17:40:14.167868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2182 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 95 finished at 2020-12-12 07:04:26.380881. Row time = 0:05:15.528141. Total time elapsed = 17:45:29.696009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 96 finished at 2020-12-12 07:24:01.781203. Row time = 0:19:35.399352. Total time elapsed = 18:05:05.095361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2212 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 97 finished at 2020-12-12 07:28:01.677397. Row time = 0:03:59.896194. Total time elapsed = 18:09:04.991555\n",
      "row 98 finished at 2020-12-12 07:47:35.050405. Row time = 0:19:33.373008. Total time elapsed = 18:28:38.364563\n",
      "row 99 finished at 2020-12-12 07:48:10.175908. Row time = 0:00:35.124501. Total time elapsed = 18:29:13.490066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 100 finished at 2020-12-12 07:49:17.767300. Row time = 0:01:07.591392. Total time elapsed = 18:30:21.081458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 101 finished at 2020-12-12 07:56:49.538948. Row time = 0:07:31.771648. Total time elapsed = 18:37:52.853106\n",
      "row 102 finished at 2020-12-12 08:09:36.275027. Row time = 0:12:46.736079. Total time elapsed = 18:50:39.589185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 103 finished at 2020-12-12 08:09:53.581768. Row time = 0:00:17.306741. Total time elapsed = 18:50:56.895926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2101 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 104 finished at 2020-12-12 08:12:33.312176. Row time = 0:02:39.729419. Total time elapsed = 18:53:36.626334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 105 finished at 2020-12-12 08:30:35.049377. Row time = 0:18:01.737201. Total time elapsed = 19:11:38.363535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1262 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 106 finished at 2020-12-12 08:33:12.495731. Row time = 0:02:37.445353. Total time elapsed = 19:14:15.809889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 107 finished at 2020-12-12 08:42:15.909757. Row time = 0:09:03.413029. Total time elapsed = 19:23:19.223915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (943 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 108 finished at 2020-12-12 08:48:58.453482. Row time = 0:06:42.543725. Total time elapsed = 19:30:01.767640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (695 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 109 finished at 2020-12-12 08:53:48.062839. Row time = 0:04:49.609357. Total time elapsed = 19:34:51.376997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1188 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 110 finished at 2020-12-12 08:56:42.194318. Row time = 0:02:54.130474. Total time elapsed = 19:37:45.508476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 111 finished at 2020-12-12 09:03:24.354220. Row time = 0:06:42.159902. Total time elapsed = 19:44:27.668378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 112 finished at 2020-12-12 09:07:22.082138. Row time = 0:03:57.726955. Total time elapsed = 19:48:25.396296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 113 finished at 2020-12-12 09:17:48.422874. Row time = 0:10:26.340736. Total time elapsed = 19:58:51.737032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (589 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 114 finished at 2020-12-12 09:23:39.656805. Row time = 0:05:51.233931. Total time elapsed = 20:04:42.970963\n",
      "row 115 finished at 2020-12-12 09:26:34.611247. Row time = 0:02:54.954442. Total time elapsed = 20:07:37.925405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 116 finished at 2020-12-12 09:27:14.558481. Row time = 0:00:39.947234. Total time elapsed = 20:08:17.872639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 117 finished at 2020-12-12 09:32:40.473626. Row time = 0:05:25.915145. Total time elapsed = 20:13:43.787784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 118 finished at 2020-12-12 09:38:01.743581. Row time = 0:05:21.269955. Total time elapsed = 20:19:05.057739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 119 finished at 2020-12-12 09:44:41.324736. Row time = 0:06:39.580154. Total time elapsed = 20:25:44.638894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 120 finished at 2020-12-12 09:48:40.708806. Row time = 0:03:59.384070. Total time elapsed = 20:29:44.022964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2761 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 121 finished at 2020-12-12 09:52:37.651760. Row time = 0:03:56.942954. Total time elapsed = 20:33:40.965918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 122 finished at 2020-12-12 10:17:09.825712. Row time = 0:24:32.173952. Total time elapsed = 20:58:13.139870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1464 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 123 finished at 2020-12-12 10:22:18.189028. Row time = 0:05:08.363316. Total time elapsed = 21:03:21.503186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 124 finished at 2020-12-12 10:33:45.411884. Row time = 0:11:27.222856. Total time elapsed = 21:14:48.726042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1351 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 125 finished at 2020-12-12 10:37:37.947073. Row time = 0:03:52.534188. Total time elapsed = 21:18:41.261231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 126 finished at 2020-12-12 10:47:47.086030. Row time = 0:10:09.138957. Total time elapsed = 21:28:50.400188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1406 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 127 finished at 2020-12-12 10:56:45.360116. Row time = 0:08:58.273117. Total time elapsed = 21:37:48.674274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 128 finished at 2020-12-12 11:08:07.473850. Row time = 0:11:22.113734. Total time elapsed = 21:49:10.788008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1225 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 129 finished at 2020-12-12 11:18:12.669789. Row time = 0:10:05.194963. Total time elapsed = 21:59:15.983947\n",
      "row 130 finished at 2020-12-12 11:27:06.879333. Row time = 0:08:54.209544. Total time elapsed = 22:08:10.193491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (11230 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 131 finished at 2020-12-12 13:14:00.772417. Row time = 1:46:53.893084. Total time elapsed = 23:55:04.086575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 132 finished at 2020-12-12 13:22:54.129126. Row time = 0:08:53.356709. Total time elapsed = 1 day, 0:03:57.443284\n",
      "row 133 finished at 2020-12-12 13:30:39.824017. Row time = 0:07:45.693928. Total time elapsed = 1 day, 0:11:43.138175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8103 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1354 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 134 finished at 2020-12-12 14:56:52.407805. Row time = 1:26:12.583788. Total time elapsed = 1 day, 1:37:55.721963\n",
      "row 135 finished at 2020-12-12 15:07:44.141059. Row time = 0:10:51.733254. Total time elapsed = 1 day, 1:48:47.455217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1888 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 136 finished at 2020-12-12 15:07:48.340849. Row time = 0:00:04.199790. Total time elapsed = 1 day, 1:48:51.655007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (994 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 137 finished at 2020-12-12 15:24:11.418764. Row time = 0:16:23.076915. Total time elapsed = 1 day, 2:05:14.732922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 138 finished at 2020-12-12 15:31:04.910326. Row time = 0:06:53.490597. Total time elapsed = 1 day, 2:12:08.224484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1591 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 139 finished at 2020-12-12 15:39:15.530710. Row time = 0:08:10.620384. Total time elapsed = 1 day, 2:20:18.844868\n",
      "row 140 finished at 2020-12-12 15:53:02.124746. Row time = 0:13:46.594036. Total time elapsed = 1 day, 2:34:05.438904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 141 finished at 2020-12-12 15:54:24.968679. Row time = 0:01:22.842932. Total time elapsed = 1 day, 2:35:28.282837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 142 finished at 2020-12-12 15:57:22.796485. Row time = 0:02:57.827806. Total time elapsed = 1 day, 2:38:26.110643\n",
      "row 143 finished at 2020-12-12 16:05:56.615603. Row time = 0:08:33.818117. Total time elapsed = 1 day, 2:46:59.929761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (913 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 144 finished at 2020-12-12 16:07:13.255801. Row time = 0:01:16.639227. Total time elapsed = 1 day, 2:48:16.569959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 145 finished at 2020-12-12 16:14:24.080342. Row time = 0:07:10.824541. Total time elapsed = 1 day, 2:55:27.394500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1458 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 146 finished at 2020-12-12 16:18:39.221859. Row time = 0:04:15.141517. Total time elapsed = 1 day, 2:59:42.536017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1981 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 147 finished at 2020-12-12 16:31:04.883140. Row time = 0:12:25.661281. Total time elapsed = 1 day, 3:12:08.197298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2116 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 148 finished at 2020-12-12 16:49:03.738215. Row time = 0:17:58.855075. Total time elapsed = 1 day, 3:30:07.052373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 149 finished at 2020-12-13 08:19:22.994583. Row time = 15:30:19.256368. Total time elapsed = 1 day, 19:00:26.308741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 150 finished at 2020-12-13 08:25:19.593741. Row time = 0:05:56.598159. Total time elapsed = 1 day, 19:06:22.907899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1281 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 151 finished at 2020-12-13 08:30:37.590240. Row time = 0:05:17.995495. Total time elapsed = 1 day, 19:11:40.904398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 152 finished at 2020-12-14 09:46:36.497095. Row time = 1 day, 1:15:58.905854. Total time elapsed = 2 days, 20:27:39.811253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 153 finished at 2020-12-14 09:48:34.381503. Row time = 0:01:57.883408. Total time elapsed = 2 days, 20:29:37.695661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1744 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 154 finished at 2020-12-14 09:50:29.436269. Row time = 0:01:55.053767. Total time elapsed = 2 days, 20:31:32.750427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 155 finished at 2020-12-14 10:02:19.244915. Row time = 0:11:49.807676. Total time elapsed = 2 days, 20:43:22.559073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 156 finished at 2020-12-14 10:04:33.009353. Row time = 0:02:13.764438. Total time elapsed = 2 days, 20:45:36.323511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 157 finished at 2020-12-14 10:08:59.161851. Row time = 0:04:26.151496. Total time elapsed = 2 days, 20:50:02.476009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4184 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 158 finished at 2020-12-14 10:11:13.236896. Row time = 0:02:14.075045. Total time elapsed = 2 days, 20:52:16.551054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (934 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 159 finished at 2020-12-14 10:44:19.032669. Row time = 0:33:05.794811. Total time elapsed = 2 days, 21:25:22.346827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 160 finished at 2020-12-14 10:49:35.674118. Row time = 0:05:16.641449. Total time elapsed = 2 days, 21:30:38.988276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (618 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 161 finished at 2020-12-14 10:52:31.414268. Row time = 0:02:55.740150. Total time elapsed = 2 days, 21:33:34.728426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1448 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 162 finished at 2020-12-14 10:54:28.353769. Row time = 0:01:56.938530. Total time elapsed = 2 days, 21:35:31.667927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 163 finished at 2020-12-14 11:03:14.200033. Row time = 0:08:45.846264. Total time elapsed = 2 days, 21:44:17.514191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 164 finished at 2020-12-14 11:05:15.376902. Row time = 0:02:01.175901. Total time elapsed = 2 days, 21:46:18.691060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1157 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 165 finished at 2020-12-14 12:04:33.931399. Row time = 0:59:18.554497. Total time elapsed = 2 days, 22:45:37.245557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1325 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 166 finished at 2020-12-14 12:11:02.342455. Row time = 0:06:28.411056. Total time elapsed = 2 days, 22:52:05.656613\n",
      "row 167 finished at 2020-12-14 12:19:16.189416. Row time = 0:08:13.845959. Total time elapsed = 2 days, 23:00:19.503574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (825 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 168 finished at 2020-12-14 12:19:54.621016. Row time = 0:00:38.431600. Total time elapsed = 2 days, 23:00:57.935174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (954 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 169 finished at 2020-12-14 12:23:49.915054. Row time = 0:03:55.294038. Total time elapsed = 2 days, 23:04:53.229212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 170 finished at 2020-12-14 12:28:38.046076. Row time = 0:04:48.131022. Total time elapsed = 2 days, 23:09:41.360234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3580 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 171 finished at 2020-12-14 12:32:22.455978. Row time = 0:03:44.408941. Total time elapsed = 2 days, 23:13:25.770136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 172 finished at 2020-12-14 12:59:15.128069. Row time = 0:26:52.672091. Total time elapsed = 2 days, 23:40:18.442227\n",
      "row 173 finished at 2020-12-14 13:08:48.450394. Row time = 0:09:33.321323. Total time elapsed = 2 days, 23:49:51.764552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 174 finished at 2020-12-14 13:09:50.752187. Row time = 0:01:02.301793. Total time elapsed = 2 days, 23:50:54.066345\n",
      "row 175 finished at 2020-12-14 13:20:47.055726. Row time = 0:10:56.303539. Total time elapsed = 3 days, 0:01:50.369884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (698 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 176 finished at 2020-12-14 13:21:23.698596. Row time = 0:00:36.642870. Total time elapsed = 3 days, 0:02:27.012754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 177 finished at 2020-12-14 13:24:33.283034. Row time = 0:03:09.584438. Total time elapsed = 3 days, 0:05:36.597192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1560 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 178 finished at 2020-12-14 13:27:38.918158. Row time = 0:03:05.635124. Total time elapsed = 3 days, 0:08:42.232316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 179 finished at 2020-12-14 13:37:46.071379. Row time = 0:10:07.153221. Total time elapsed = 3 days, 0:18:49.385537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 180 finished at 2020-12-14 14:34:08.798139. Row time = 0:56:22.726760. Total time elapsed = 3 days, 1:15:12.112297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 181 finished at 2020-12-14 14:41:03.495663. Row time = 0:06:54.696556. Total time elapsed = 3 days, 1:22:06.809821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 182 finished at 2020-12-14 14:44:18.582742. Row time = 0:03:15.086082. Total time elapsed = 3 days, 1:25:21.896900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (861 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 183 finished at 2020-12-14 14:50:37.818028. Row time = 0:06:19.235286. Total time elapsed = 3 days, 1:31:41.132186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 184 finished at 2020-12-14 14:55:00.419992. Row time = 0:04:22.601964. Total time elapsed = 3 days, 1:36:03.734150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2597 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 185 finished at 2020-12-14 15:02:16.147372. Row time = 0:07:15.726383. Total time elapsed = 3 days, 1:43:19.461530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 186 finished at 2020-12-14 15:23:58.978729. Row time = 0:21:42.831357. Total time elapsed = 3 days, 2:05:02.292887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3220 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 187 finished at 2020-12-14 15:27:31.073650. Row time = 0:03:32.093919. Total time elapsed = 3 days, 2:08:34.387808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2440 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 188 finished at 2020-12-14 15:53:23.676096. Row time = 0:25:52.602446. Total time elapsed = 3 days, 2:34:26.990254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1113 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 189 finished at 2020-12-14 16:14:10.075519. Row time = 0:20:46.399398. Total time elapsed = 3 days, 2:55:13.390650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1185 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 190 finished at 2020-12-14 16:21:22.870445. Row time = 0:07:12.793953. Total time elapsed = 3 days, 3:02:26.184603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2603 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 191 finished at 2020-12-14 16:29:13.124331. Row time = 0:07:50.253886. Total time elapsed = 3 days, 3:10:16.438489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 192 finished at 2020-12-14 16:49:01.412786. Row time = 0:19:48.288455. Total time elapsed = 3 days, 3:30:04.726944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2203 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 193 finished at 2020-12-14 17:02:23.540524. Row time = 0:13:22.127738. Total time elapsed = 3 days, 3:43:26.854682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1649 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 194 finished at 2020-12-14 17:21:25.539740. Row time = 0:19:01.998216. Total time elapsed = 3 days, 4:02:28.853898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2099 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 195 finished at 2020-12-14 17:32:15.319131. Row time = 0:10:49.779391. Total time elapsed = 3 days, 4:13:18.633289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 196 finished at 2020-12-14 17:48:53.835727. Row time = 0:16:38.515595. Total time elapsed = 3 days, 4:29:57.149885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (684 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 197 finished at 2020-12-14 17:53:53.230624. Row time = 0:04:59.393898. Total time elapsed = 3 days, 4:34:56.544782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 198 finished at 2020-12-14 17:56:57.842485. Row time = 0:03:04.610903. Total time elapsed = 3 days, 4:38:01.156643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 199 finished at 2020-12-14 18:01:01.713301. Row time = 0:04:03.869850. Total time elapsed = 3 days, 4:42:05.027459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 200 finished at 2020-12-14 18:05:05.512137. Row time = 0:04:03.797840. Total time elapsed = 3 days, 4:46:08.826295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2156 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 201 finished at 2020-12-14 18:13:04.272713. Row time = 0:07:58.760576. Total time elapsed = 3 days, 4:54:07.586871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 202 finished at 2020-12-15 08:07:08.658846. Row time = 13:54:04.386133. Total time elapsed = 3 days, 18:48:11.973004\n",
      "row 203 finished at 2020-12-15 08:13:44.731943. Row time = 0:06:36.073097. Total time elapsed = 3 days, 18:54:48.046101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10625 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 204 finished at 2020-12-15 10:28:08.589801. Row time = 2:14:23.858849. Total time elapsed = 3 days, 21:09:11.904950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3490 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1373 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 205 finished at 2020-12-15 10:56:03.442882. Row time = 0:27:54.851090. Total time elapsed = 3 days, 21:37:06.757040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 206 finished at 2020-12-15 11:04:44.051604. Row time = 0:08:40.607721. Total time elapsed = 3 days, 21:45:47.365762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3925 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 207 finished at 2020-12-15 11:06:58.611048. Row time = 0:02:14.558431. Total time elapsed = 3 days, 21:48:01.925206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 208 finished at 2020-12-15 11:39:10.082456. Row time = 0:32:11.471408. Total time elapsed = 3 days, 22:20:13.396614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1491 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 209 finished at 2020-12-15 11:42:28.118076. Row time = 0:03:18.035623. Total time elapsed = 3 days, 22:23:31.433237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (769 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 210 finished at 2020-12-15 11:53:12.485577. Row time = 0:10:44.366498. Total time elapsed = 3 days, 22:34:15.799735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 211 finished at 2020-12-15 11:58:02.551096. Row time = 0:04:50.065519. Total time elapsed = 3 days, 22:39:05.865254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6804 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 212 finished at 2020-12-15 12:04:04.176371. Row time = 0:06:01.624274. Total time elapsed = 3 days, 22:45:07.490529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1893 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 213 finished at 2020-12-15 13:06:44.820389. Row time = 1:02:40.644018. Total time elapsed = 3 days, 23:47:48.134547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1983 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 214 finished at 2020-12-15 13:20:05.032448. Row time = 0:13:20.210058. Total time elapsed = 4 days, 0:01:08.346606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 215 finished at 2020-12-15 13:34:59.817391. Row time = 0:14:54.784943. Total time elapsed = 4 days, 0:16:03.131549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 216 finished at 2020-12-15 13:38:35.563280. Row time = 0:03:35.744893. Total time elapsed = 4 days, 0:19:38.877438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1117 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 217 finished at 2020-12-15 13:46:27.942153. Row time = 0:07:52.377912. Total time elapsed = 4 days, 0:27:31.256311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1275 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 218 finished at 2020-12-15 13:53:32.618936. Row time = 0:07:04.676783. Total time elapsed = 4 days, 0:34:35.933094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1730 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 219 finished at 2020-12-15 14:02:44.007692. Row time = 0:09:11.388756. Total time elapsed = 4 days, 0:43:47.321850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 220 finished at 2020-12-15 14:16:12.861058. Row time = 0:13:28.853366. Total time elapsed = 4 days, 0:57:16.175216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 221 finished at 2020-12-15 14:18:42.467552. Row time = 0:02:29.606494. Total time elapsed = 4 days, 0:59:45.781710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2028 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 222 finished at 2020-12-15 14:22:06.009103. Row time = 0:03:23.541551. Total time elapsed = 4 days, 1:03:09.323261\n"
     ]
    }
   ],
   "source": [
    "start_time=datetime.now()\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    row_start = datetime.now()\n",
    "    process_row(row_id=i, \n",
    "                model=model, \n",
    "                tokenizer=tokenizer, \n",
    "                questions=questions, \n",
    "                max_batch_size=2, \n",
    "                max_model_tokens=512, \n",
    "                stride=128)\n",
    "    df.to_parquet('df_with_segments.parquet')\n",
    "    print(f'row {i} finished at {datetime.now()}. Row time = {datetime.now() - row_start}. Total time elapsed = {datetime.now() - start_time}')\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
